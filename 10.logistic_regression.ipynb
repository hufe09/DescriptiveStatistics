{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逻辑回归 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拟合逻辑回归  Fitting Logistic Regression\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.qxa8hgdsiis.png)\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.7fk75lg9f8q.png)\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.k3gqmi0y02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.m7njylss6d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python拟合逻辑回归\n",
    "\n",
    "在第一个 notebook 中，你将对一个数据集拟合一个逻辑回归模型，从而预测一个交易中是否存在欺诈行为。\n",
    "\n",
    "首先，我们导入库，并快速浏览一下数据集，然后开始你的任务吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>day</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28891</td>\n",
       "      <td>21.302600</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61629</td>\n",
       "      <td>22.932765</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53707</td>\n",
       "      <td>32.694992</td>\n",
       "      <td>weekday</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47812</td>\n",
       "      <td>32.784252</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43455</td>\n",
       "      <td>17.756828</td>\n",
       "      <td>weekend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id   duration      day  fraud\n",
       "0           28891  21.302600  weekend  False\n",
       "1           61629  22.932765  weekend  False\n",
       "2           53707  32.694992  weekday  False\n",
       "3           47812  32.784252  weekend  False\n",
       "4           43455  17.756828  weekend  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv('datasets/fraud_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 正如你所见，有两列需要更改为虚拟变量。将每个当前列替换为虚拟变量。1代表 `weekday` 与 `True`，  0 代表其他。使用第一个测试题目来回答关于数据集的几个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = pd.get_dummies(df['day'])['weekday']\n",
    "df[['not_fraud','fraud']] = pd.get_dummies(df['fraud'])\n",
    "df = df.drop('not_fraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012168770612987604\n",
      "0.3452746502900034\n",
      "fraud\n",
      "0    30.013583\n",
      "1     4.624247\n",
      "Name: duration, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['fraud'].mean())\n",
    "print(df['weekday'].mean())\n",
    "print(df.groupby('fraud').mean()['duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 现在你已经有了虚拟变量，可以使用逻辑回归模型来预测一个交易是否利用日期和持续时间进行欺诈。 不要忘记添加一个截距！ 回答下面的第二个测试题目，确保你拟合的模型是正确的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/statsmodels/discrete/discrete_model.py:1724: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q*np.dot(X,params))))\n",
      "/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: inf\n",
      "         Iterations 16\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  fraud   No. Observations:                 8793\n",
      "Model:                          Logit   Df Residuals:                     8790\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Mon, 15 Jul 2019   Pseudo R-squ.:                     inf\n",
      "Time:                        11:44:19   Log-Likelihood:                   -inf\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "                                        LLR p-value:                     1.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept      9.8709      1.944      5.078      0.000       6.061      13.681\n",
      "weekday        2.5465      0.904      2.816      0.005       0.774       4.319\n",
      "duration      -1.4637      0.290     -5.039      0.000      -2.033      -0.894\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.98 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/statsmodels/base/model.py:488: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n"
     ]
    }
   ],
   "source": [
    "df['intercept'] = 1\n",
    "log_mod = sm.Logit(df['fraud'], df[['intercept', 'weekday', 'duration']])\n",
    "results = log_mod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2313785882117941, 12.762357271496972)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-1.4637), np.exp(2.5465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.321921089278333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(-1.4637)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何解释这些系数，我们首先需要对每个系数进行指数化，现在每个值结果是对几率的乘数变化，例如对于工作日虚拟变量在工作日\n",
    "\n",
    "诈骗为12.76乘以周末的值，其他变量保持不变，我们也解释时长的系数，因为页面上时长每增加1个单位，诈骗增加0.23倍，其他变量保持不变，当你得到乘数变化小于1时，正如这里对时长的运算(0.2313785882117941)，计算倒数非常有效，这改变了单位增加的方向，变为单位降低，所以页面上时长每降低1个单位，诈骗增加4.32倍，在这个案例中结果是工作日或周末，这种倒数可以帮助受众更好地联系结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.w0znizgq56m.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 解释逻辑回归的结果\n",
    "\n",
    "在这个 notebook 与 测试题中，你将做一些解释逻辑回归系数的练习。在前面的视频中看到的内容，应该有助于你完成该 notebook 。\n",
    "\n",
    "该数据集包含四个变量： `admit`、 `gre`、 `gpa` 与 `prestige`\n",
    "\n",
    "* `admit` 是一个二元变量，它表明一个候选人是否被 UCLA 录取，录取=1，不被录取=0 。\n",
    "* `gre` 代表 GRE 成绩，GRE 指的是研究生入学考试。\n",
    "* `gpa` 代表平均学分绩点 （Grade Point Average）。\n",
    "* `prestige` 代表申请人母校（此次申请之前申请人曾就读的学校）的声誉，其中1代表最高（声誉最高），4代表最低（没有声誉）。\n",
    "\n",
    "首先，让我们导入必要的库和数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige\n",
       "0      0  380  3.61         3\n",
       "1      1  660  3.67         3\n",
       "2      1  800  4.00         1\n",
       "3      1  640  3.19         4\n",
       "4      0  520  2.93         4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(\"datasets/admissions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有几种不同的方法，你可以选择其中一个在这个数据集中使用 `prestige` 列。对于这个数据集，我们希望从声誉1到声誉2，有一个录取率；从声誉3变为声誉4，有一个不同的录取率。\n",
    "\n",
    "1. 有了上述的想法之后，创建几个虚拟变量，这几个变量可以把声誉改成一个分类变量，而不是定量，然后回答下面的测试1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>prest_1</th>\n",
       "      <th>prest_2</th>\n",
       "      <th>prest_3</th>\n",
       "      <th>prest_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige  prest_1  prest_2  prest_3  prest_4\n",
       "0      0  380  3.61         3        0        0        1        0\n",
       "1      1  660  3.67         3        0        0        1        0\n",
       "2      1  800  4.00         1        1        0        0        0\n",
       "3      1  640  3.19         4        0        0        0        1\n",
       "4      0  520  2.93         4        0        0        0        1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['prest_1', 'prest_2', 'prest_3','prest_4',]] = pd.get_dummies(df['prestige'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    148\n",
       "3    121\n",
       "4     67\n",
       "1     61\n",
       "Name: prestige, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prestige'].astype(str).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 现在，拟合一个逻辑回归模型，使用 `gre`、 `gpa` 以及使用基准值为 `1`的  `prestige` 来预测一个人是否会被录取。根据你的结果来回答下面的测试2和3。 不要忘记添加一个截距。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                  admit   No. Observations:                  397\n",
      "Model:                          Logit   Df Residuals:                      391\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Mon, 15 Jul 2019   Pseudo R-squ.:                 0.08166\n",
      "Time:                        11:53:36   Log-Likelihood:                -227.82\n",
      "converged:                       True   LL-Null:                       -248.08\n",
      "                                        LLR p-value:                 1.176e-07\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "intercept     -3.8769      1.142     -3.393      0.001      -6.116      -1.638\n",
      "gre            0.0022      0.001      2.028      0.043    7.44e-05       0.004\n",
      "gpa            0.7793      0.333      2.344      0.019       0.128       1.431\n",
      "prest_2       -0.6801      0.317     -2.146      0.032      -1.301      -0.059\n",
      "prest_3       -1.3387      0.345     -3.882      0.000      -2.015      -0.663\n",
      "prest_4       -1.5534      0.417     -3.721      0.000      -2.372      -0.735\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "df['intercept'] = 1\n",
    "\n",
    "logit_mod = sm.Logit(df['admit'], df[['intercept','gre', 'gpa', 'prest_2', 'prest_3', 'prest_4']])\n",
    "results = logit_mod.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.020716\n",
       "gre          1.002221\n",
       "gpa          2.180027\n",
       "prest_2      0.506548\n",
       "prest_3      0.262192\n",
       "prest_4      0.211525\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    48.272116\n",
       "gre           0.997784\n",
       "gpa           0.458710\n",
       "prest_2       1.974147\n",
       "prest_3       3.813995\n",
       "prest_4       4.727566\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prestige\n",
       "1    0.540984\n",
       "2    0.358108\n",
       "3    0.231405\n",
       "4    0.179104\n",
       "Name: admit, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('prestige').mean()['admit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.mzspgnfqr5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "确定逻辑回归模型如何，较好地预测正确标记时，最常见的测量方法称为**准确率**，准确率是正确标记的行数，除以数据集中的总行数的比例，有些情况下准确率并不能较好发挥作用，尤其是数据集中存在大量不均衡时，记住这一点 Sebastian 将要复习其他一些常用衡量标准，以及如何理解，你的模型可以较好地符合这些衡量标准，这个视频中一些参考资料并不适用于这节课，因为这些信息是，下面讲师注释提供的链接中免费的机器学习课程的一部分，一旦 Sebastian 向你展示这些衡量标准，我们可以一起在 Python 中使用它们\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.snx72g12vk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Udacity的机器学习课程](https://www.udacity.com/course/intro-to-machine-learning--ud120)是一个很好的方式来开始与这两个课程相关的想法，以及演示一些更先进的技术。\n",
    "\n",
    "该[机器学习Nanodegree](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009)是这个节目之后的另一个巨大的进步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrices 混淆矩阵\n",
    "\n",
    "现在要讨论**混淆矩阵**，你可能未曾听说过这个名词 但如果要从事机器学习并向别人讨论这个的话，这是个很好的词汇，想象我们有一个分类器 在这条线上方 是红色的X 线下方是绿色的圈，想象我们有一个分类器 在这条线上方 是红色的X 线下方是绿色的圈，与以前一样 我们将红色 X 称为正例示例，绿环为负例，**混淆矩阵是一个二乘二的矩阵**，对照实际类 它可为正例或负例，这个概念 我们称为一个**预测类**，它是我们的输出值 也可以为正例或负例，右边的点的数量将会增加左边的计数，我们观察一下，我们在这里取一个数据点为负例，其分类位于该分类器的绿色一侧，如果要对这种类型的数据进行计数，那它会落入左侧四个位置的哪一个里？\n",
    "\n",
    "实际类是负例的 但是分类器也将它放入负例的一侧\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.swexno6jh1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.zz9q9cgni47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然 对于误归类的点来说事情变得更加困难，所以我们来看下这里的这个点，我们来把它加入(到图里)，那它会落入左侧的什么位置？\n",
    "\n",
    "这个数据点是真阳性，它是个红十字 但被预测为负例，所以 真正的实际正例被预测为负例\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.w901m5dnd9d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.wtv31oxogz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 虚假报警\n",
    "因此 在这里我有最后一个问题，假设这是一个报警系统 正向或者正例意味着，你们的房子里有一个盗贼，你们认为哪个框 什么类型的事件，最能说明报警系统的假警报的特点？\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.4fgcbq7b683.png)\n",
    "\n",
    "我说是误报警 是因为报警响了 即正例表示了盗窃行为，但实际并没有盗贼，在真实世界中事件是负例 但系统说是正例，所以在这里要画勾 你可以看出有点不对称\n",
    "\n",
    "可以看出你可能关心给你正例报警的负例事件，不同于被错过的正例事件，先提前给大家透露一点知识，通常 通过改变参数 可将这个曲线向两个方向变动，如果你认为那是误报警 其会导致警察来你家捉贼，其代价应不同于被错过的事件，后者的一个例子是有人抢走了你的物品 而警察却一无所知，这时 你可能希望将这条线重新上下调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征脸的混淆矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比如我们查看七个不同的白人男性政治家，从 George Bush 到 Gerhard Schroeder 然后进行 EigenFace 分析，提取出此数据集的主成分 然后再使用Eigenfaces 对应着姓名重新绘制新的面部图 从而识别这些人。我们不管这些面部图，我要做的是给你一个有典型的输出，我们将使用混淆矩阵学习输出\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.ozkcoujanp.png)\n",
    "\n",
    "我们在左侧放置正确的姓名 正确的类型标签，在上方放置预测的内容，比如说 这里的数字 1 对应的是 Donald Rumsfeld，但被错误地认为是 Colin Powell\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.8mb3359nugg.png)\n",
    "\n",
    "首先 一个简单的问题，这七个政治家中 哪个在我们的数据集中出现次数最多？　\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.0js178l6l9e.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个问题Gerhard Schroeder在我们的数据集中有多少张图像？\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.azcku14x55w.png)\n",
    "\n",
    "预测这一边有多少认为是Gerhard Schroeder图像的预测？\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.5aqos2swrbm.png)\n",
    "\n",
    "答案是 15，就是这一列 14 加 1，这让你多少能了解这些数据，很明显 在混淆矩阵中，如果主对角线上有最大值 你会十分高兴，因为所有非对角线元素被错误分类\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.i30ja3b692.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确分类Hugo，学习算法正确分类Hugo的概率？\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.agdcdhnq7we.png)\n",
    "\n",
    "现在我问个不同的问题，假如你的预测器说这是 Hugo Chavez，运行学习算法 算法也将它分类为 Hugo Chavez，那么这个人真的是 Hugo Chavez 的概率有多大？\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.6in5i1lt3a.png)\n",
    "\n",
    "概率恰好是 1，似乎结果完美地正确预测了 Hugo Chavez，如果你查看所有由算法识别出的 Hugo Chavez 的图像案例，10 个里有 10 个都是对的结果，所以 10 除以 10 等于 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 查全率和查准率 Precision and Recall\n",
    "我们来看两个专业术语,查全率和查准率,,例如 假设此人就是 Hugo Chavez\n",
    "\n",
    "那么 Hugo Chavez 的查全率就是准确识别的次数比率,即在这个人是 Hugo Chavez 的情况下 我们的算法准确识别 Hugo Chavez 的概率,因此 我们得出的结果是 10/16\n",
    "\n",
    "\n",
    "查准率也是比率概念,是我们的算法预测的概率 是我们学习的第二个比率,这里恰好是 1,假设我们的算法检测到了 Hugo Chavez,那么此人确实是 Hugo Chavez 的概率,这里的查准率刚好是 10/10\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.td0t0i3s8j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Positives in Eigenfaces\n",
    "\n",
    "False Positives in Eigenfaces\n",
    "\n",
    "False Negatives in Eigenfaces\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.17g0wak374l.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation for Precision 查全率方程\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.kiimi6edl1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equation for Recall 查准率方程\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.v8rf2emrd2l.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python中的模型诊断 Model Diagnostics in Python \n",
    "\n",
    "Model Diagnostics.ipynb\n",
    "\n",
    "In this notebook, you will be trying out some of the model diagnostics you saw from Sebastian, but in your case there will only be two cases - either admitted or not admitted.\n",
    "\n",
    "First let's read in the necessary libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  prestige\n",
       "0      0  380  3.61         3\n",
       "1      1  660  3.67         3\n",
       "2      1  800  4.00         1\n",
       "3      1  640  3.19         4\n",
       "4      0  520  2.93         4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_csv('datasets/admissions.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` Change prestige to dummy variable columns that are added to `df`.  Then divide your data into training and test data.  Create your test set as 20% of the data, and use a random state of 0.  Your response should be the `admit` column.  [Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) are the docs, which can also find with a quick google search if you get stuck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['prest_1', 'prest_2', 'prest_3', 'prest_4']] = pd.get_dummies(df['prestige'])\n",
    "X = df.drop('admit', axis=1)\n",
    "y = df['admit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "          X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` Now use [sklearn's Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to fit a logistic model using `gre`, `gpa`, and 3 of your `prestige` dummy variables.  For now, fit the logistic regression model without changing any of the hyperparameters.  \n",
    "\n",
    "The usual steps are:\n",
    "* Instantiate\n",
    "* Fit (on train)\n",
    "* Predict (on test)\n",
    "* Score (compare predict to test)\n",
    "\n",
    "As a first score, obtain the [confusion matrix](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html).  Then answer the first question below about how well your model performed on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[55,  1],\n",
       "       [17,  7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mod = LogisticRegression()\n",
    "log_mod.fit(X_train, y_train)\n",
    "preds = log_mod.predict(X_test)\n",
    "confusion_matrix(y_test, preds) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`3.` Now, try out a few additional metrics: [precision](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html), [recall](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html), and [accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) are all popular metrics, which you saw with Sebastian.  You could compute these directly from the confusion matrix, but you can also use these built in functions in sklearn.\n",
    "\n",
    "Another very popular set of metrics are [ROC curves and AUC](http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html#sphx-glr-auto-examples-model-selection-plot-roc-py).  These actually use the probability from the logistic regression models, and not just the label.  [This](http://blog.yhat.com/posts/roc-curves.html) is also a great resource for understanding ROC curves and AUC.\n",
    "\n",
    "Try out these metrics to answer the second quiz question below.  I also provided the ROC plot below.  The ideal case is for this to shoot all the way to the upper left hand corner.  Again, these are discussed in more detail in the Machine Learning Udacity program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2916666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'tslib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-783c3c8a5b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_mod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeoms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_blank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_boxplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_jitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_histogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_density\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_hline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_vline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_abline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_rect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_bin2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_ribbon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_now_its_art\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_violin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_errorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_polygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstat_smooth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat_density\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/geoms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom_abline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_abline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom_area\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_area\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom_bar\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom_bin2d\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_bin2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom_blank\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom_blank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/geoms/geom_abline.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgeom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mgeom_abline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"\n\u001b[1;32m      5\u001b[0m     \u001b[0mLine\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mby\u001b[0m \u001b[0mslope\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/geoms/geom.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m from __future__ import (absolute_import, division, print_function,\n\u001b[1;32m      2\u001b[0m                         unicode_literals)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mggplot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/ggplot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0maes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_legend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mthemes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtheme_gray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/aes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpatsy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/ggplot/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m date_types = (\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtslib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPeriod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'tslib'"
     ]
    }
   ],
   "source": [
    "from ggplot import *\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "%matplotlib inline\n",
    "\n",
    "preds = log_mod.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, preds)\n",
    "\n",
    "df = pd.DataFrame(dict(fpr=fpr, tpr=tpr))\n",
    "ggplot(df, aes(x='fpr', y='tpr')) +\\\n",
    "    geom_line() +\\\n",
    "    geom_abline(linetype='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来 ggplot(又称ggpy)是一个官方不再维护的项目了, github上的最近一次提交还是三年前\n",
    "\n",
    "https://segmentfault.com/q/1010000018525241/a-1020000018525816\n",
    "\n",
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.0e903xs0x1m8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/hufe09/GitNote-Images/master/Picee/image.wd6r6zqpq9p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 复习\n",
    "\n",
    "以上就是实用统计学的所有内容了！这两节课讲的是多元线性回归和逻辑回归，但你看到的大多数内容已经开始朝**数据科学** 靠拢了，也就是说，大部分内容已经超越了多数日常 **数据分析** 的范畴了。不过，我希望这两节课的一些挑战给你带来了愉快的体验。 \n",
    "\n",
    "这两节课初步介绍的两种办法——多元线性回归和逻辑回归，只是监督机器学习的一部分。你可以从[优达学城免费课程](https://classroom.udacity.com/courses/ud120)中了解更多，又或者可以在[机器学习纳米学位课程](https://www.udacity.com/course/machine-learning-engineer-nanodegree--nd009) 中查看项目回顾以及优达学城的社区信息。 \n",
    "\n",
    "在本课中，我们学习了逻辑回归，你学到了： \n",
    "\n",
    "1. 如何使用 python 来实现逻辑回归，用 statsmodels 和 sklearn 包来预测二元分类反应值。 \n",
    "2. 如何解释 statsmodels 逻辑回归输出的系数。 \n",
    "3. 如何用多个指标来评估模型效果。 \n",
    "4. 如何在 python 里评估模型拟合效果。 \n",
    "\n",
    "你已经学到了很多了！恭喜你！祝你在项目中取得好成绩！ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑回归** 课程中 **抽样分布** 的 notebook 方案和数据可见本页底部。 \n",
    "\n",
    "辅助材料 \n",
    "\n",
    " [Practical Statistics](https://d17h27t6h515a5.cloudfront.net/topher/2017/November/5a1c8935_practical-statistics/practical-statistics.zip) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
